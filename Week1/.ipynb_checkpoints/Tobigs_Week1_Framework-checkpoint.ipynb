{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리와 프레임워크는 이미 검증된 코드와 시스템 및 설계 위에서 코딩을 하여 시간을 단축하고 통일성이 생긴다는 공통점이 존재한다. 하지만 프레임워크는 하나의 작업공간이며 주어지는 도구들만을 사용하여 코드를 구축해나가야한다. 반대로 라이브러리같은 경우는 본인이 코드를 칠 때 하나의 도구로서 활용이 가능한 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 데이터를 기반으로 학습하여 추론하는 기술이며, 딥러닝은 머신러닝의 기술 중 하나이다. 하지만 딥러닝과 머신러닝에는 확실한 차이가 있는데 바로 사람의 개입이 들어가는지에 대한 유무이다. 머신러닝의 경우에는 컴퓨터가 학습하기전 여러가지 특징들을 미리 전처리 과정을 통해 분석해야 한다. 반대로 딥러닝의 경우에는 따로 패턴을 분석하고 특징을 추출하는 사람의 개입이 없어지며, 만들어진 신경망에 데이터를 입력하여 예측하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "# 사용 가능한 gpu가 있을 때만 cuda 연산 할당\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 시드 고정\n",
    "torch.manual_seed(45)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100 \n",
    "num_classes = 10 # 총 분류할 클래스의 개수 : 10개\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 불러오기(MNIST)\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() \n",
    "    ])\n",
    ")\n",
    "\n",
    "# 테스트 데이터 불러오기(MNIST)\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 생성\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(ConvNet, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # input_channel : 1, output_channel : 10, kernel_size : 5\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) # 0.25% 만큼 dropout\n",
    "        self.mp = nn.MaxPool2d(2)  # 0.5 만큼 size 축소\n",
    "        self.fc1 = nn.Linear(320,100)  # input_channel : 320, output_channel : 100\n",
    "        self.fc2 = nn.Linear(100,10) # 출력되는 channel 개수 = class 개수\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) # convolution -> maxpooling -> ReLu\n",
    "        x = F.relu(self.mp(self.conv2(x))) # convolution -> maxpooling -> ReLu\n",
    "        x = self.drop2D(x) # dropout\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.fc1(x)  # fcLayer\n",
    "        x = self.fc2(x)  # fcLayer\n",
    "        return F.log_softmax(x)  # softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device) # model class -> device 환경\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # 손실함수 : Cross Entropy -> device 환경\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)  # Optimizer : Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device) # data -> device\n",
    "        target = target.to(device)  # label -> device\n",
    "        optimizer.zero_grad() # gradient 0으로 초기화\n",
    "        hypothesis = model(data) # data -> model\n",
    "        cost = criterion(hypothesis, target) # 손실함수 계산(output, target)\n",
    "        cost.backward() # 가중치와 편향에 대한 기울기 계산\n",
    "        optimizer.step()  # 기울기를 이용하여 업데이트\n",
    "        avg_cost += cost / len(train_loader)  # loss 값 평균\n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.eval()  # test 작업 시작\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)  # data -> device\n",
    "        target = target.to(device)  # target -> device\n",
    "        out = model(data)  # data -> model\n",
    "        preds = torch.max(out.data, 1)[1]  # predict\n",
    "        total += len(target) # target 개수 (누적)\n",
    "        correct += (preds==target).sum().item() # 예측값이 정답인 경우 (누적)\n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%') # 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
